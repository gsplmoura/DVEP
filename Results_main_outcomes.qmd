---
title: "Main outcomes"
author: "S.P.L.M., Gustavo"
date: today
format:
  html:
    toc: true
    toc-depth: 2
    toc-float:
      collapsed: false
      smooth-scroll: true
  pdf:
    toc: true
    toc-depth: 2
    pdf-engine: xelatex
---

# Getting started

## Load data

```{r}
rm(list = ls())
graphics.off()
cat("\014")  # Clear any pending RStudio sessions or temporary files

# Load functions from external script
source("helper_functions.R")

## Load necessary libraries
library(tidyverse)
library(readxl)
library(lubridate)
library(stringr)
library(purrr)
library(here)
library(lme4)
library(lmerTest)
library(skimr)

# Read Files ----
## Codebooks
codebook_dvep <- read_excel(
    "Codebooks/codebook_dvep.xlsx",
    col_names = TRUE,
    col_types = NULL,
    na = c("", "NA", "NI", "UNK", "NASK", "ASKU", "INV"),
    trim_ws = TRUE,
    skip = 0, # Number of lines to skip before reading data
    n_max = Inf, # Maximum number of lines to read.
    guess_max = 1000
) %>%
    arrange(index)

codebook_structure  <- read_csv(
    "Codebooks/codebook_structure.csv",
    col_names = TRUE)

codebook_ncit  <- read_csv(
    "Codebooks/codebook_ncit.csv",
    col_names = TRUE)

codebook_bia <- read_excel(
    "Codebooks/codebook_bia.xlsx",
    col_names = TRUE,
    col_types = NULL,
    na = c("", "NA", "NI", "UNK", "NASK", "ASKU", "INV"),
    trim_ws = TRUE,
    skip = 0, # Number of lines to skip before reading data
    n_max = Inf, # Maximum number of lines to read.
    guess_max = 1000
) %>%
    arrange(index)

## Data
data <- readRDS("Data_processed/data.rds")
data_bia <- readRDS("Data_processed/data_bia.rds")
data_bia_D1 <- readRDS("Data_processed/data_bia_D1.rds")
data_bia_D1_mean <- readRDS("Data_processed/data_bia_D1_mean.rds")
data_bia_D1_raw <- readRDS("Data_processed/data_bia_D1_raw.rds")
data_bia_D3 <- readRDS("Data_processed/data_bia_D3.rds")
data_bia_D3_mean <- readRDS("Data_processed/data_bia_D3_mean.rds")
data_bia_D3_raw <- readRDS("Data_processed/data_bia_D3_raw.rds")
data_bia_mean <- readRDS("Data_processed/data_bia_mean.rds")
data_d1_exclusive <- readRDS("Data_processed/data_d1_exclusive.rds")
data_filtered <- readRDS("Data_processed/data_filtered.rds")
data_filtered_seca <- readRDS("Data_processed/data_filtered_seca.rds")
I21_conditions_R <- readRDS("Data_processed/I21_conditions_R.rds")
I22_drugs_R <- readRDS("Data_processed/I22_drugs_R.rds")
I27_labs_R <- readRDS("Data_processed/I27_labs_R.rds")
I29_compliance_new <- readRDS("Data_processed/I29_compliance_new.rds")
I30_events_R <- readRDS("Data_processed/I30_events_R.rds")

## SUPERTIBBLE
data_instruments <- readRDS("Data_instruments/data_instruments.rds")
```

## Variables of interest

- (1 \| record_id) + visit + allocation_group + age + sex + race + education +
- Comorbidities: hypertension + hypercholesterolemia + hypertrigliceridemia + insulin + drugs_w_loss + drugs_w_gain
- Anthro: abdomen + bmi + mean_bp_mean
- Questionnaires: whoqol_score_overall + ecap_score + evs_score + dass_score_stress + dass_score_anxiety + dass_score_depression + alcohol_significant + smoke_history + carbs_kcal + protein_kcal + fat_kcal + drugs_dose_change_yn +
- Ades√£o: completed_intervention, intervention_duration, education_years? cp_taking_as_directed_yn, cp_missed_dose_yn, cp_missed_dose_count, cp_discontinued_yn, cp_discontinued_n_days, cp_ran_out_of_drug_yn, cp_medication_confidence_sca


## Select variables

```{r}
data_model <- data_filtered %>% 
    select(
        record_id:sex,
        hypertension:ecap_score,
        abdomen, bmi, mean_bp_mean,
        resistance:evs_score,
        alcohol_dose, 
        carbs_kcal, protein_kcal, fat_kcal, kcal,
        labs_crp:labs_alkp,
        labs_cholesterol:labs_quick_index
    )

saveRDS(
    data_model,
    "Data_processed/data_model.rds")

vars_to_keep <- names(data_model)

# Step 2: filter codebook_dvep
codebook_data_model <- codebook_dvep %>%
    filter(variable %in% vars_to_keep) %>% 
    select(
        variable, label_pt, field_type, choices)

saveRDS(
    codebook_data_model,
    "Data_processed/codebook_data_model.rds")
```

## Scaling

$${QUICKI} = \frac{1}{\\log(insulin) + log(glucose)}$$

$$
HOMA-IR = \frac{insulin * glucose}{405}
$$

```{r}
data_model_scaled <- data_model %>%
  mutate(across(
    .cols = c(
        duration_difference, age,
        whoqol_score_overall, dass_score_depression, dass_score_anxiety,
        dass_score_stress, ecap_score, 
        abdomen, bmi, mean_bp_mean,
        resistance, reactance, 
        handgrip, evs_score, alcohol_dose,
        carbs_kcal, protein_kcal, fat_kcal, kcal,
        labs_crp, labs_ast, labs_alt, labs_ggt, labs_alkp,
        labs_cholesterol, labs_ldl, labs_hba1c, labs_triglycerides,
        labs_hdl, labs_glucose, labs_insulin, labs_homa_ir
    ),
    .fns = ~ as.numeric(scale(.))
  ))

scaling_params <- data_model %>%
  summarise(across(
    .cols = c(
      duration_difference, age,
      whoqol_score_overall, dass_score_depression, dass_score_anxiety,
      dass_score_stress, ecap_score, 
      abdomen, bmi, mean_bp_mean,
      resistance, reactance, 
      handgrip, evs_score, alcohol_dose,
      carbs_kcal, protein_kcal, fat_kcal,
      labs_crp, labs_ast, labs_alt, labs_ggt, labs_alkp,
      labs_cholesterol, labs_ldl, labs_hba1c, labs_triglycerides,
      labs_hdl, labs_glucose, labs_insulin, labs_homa_ir
    ),
    list(mean = ~mean(., na.rm = TRUE), sd = ~sd(., na.rm = TRUE))
  )) %>%
  pivot_longer(everything(),
               names_to = c("variable", ".value"),
               names_sep = "_(?=[^_]+$)",  # üëà this fixes the splitting
               names_transform = list(.value = as.character))
```

```{r, eval=FALSE}
# THEN, FOR NEW DATA
scale_with_params <- function(new_data, params) {
  for (i in seq_len(nrow(params))) {
    var <- params$variable[i]
    mean_val <- params$mean[i]
    sd_val <- params$sd[i]
    if (var %in% names(new_data)) {
      new_data[[var]] <- (new_data[[var]] - mean_val) / sd_val
    }
  }
  return(new_data)
}

new_data_scaled <- scale_with_params(new_data, scaling_params)
```

# Phase angle

Filtrando D1 and D3

```{r}
pha_redcap <- data_model_scaled %>% 
    filter(
        visit %in% c(1, 3)
    ) %>% 
    mutate(
        compliance_score_visit = case_when(
            visit == 3 & completed_intervention == "N√£o" ~ 0,
            TRUE ~ compliance_score_visit
        )
    )
```

## All variables

```{r}
library(lme4)
library(lmerTest) # Adds p-values to summary()
```

```{r}
pha_1 <- lmer(phase_angle ~ (1 | record_id) + visit + allocation_group + completed_intervention + duration_difference + age + sex + hypertension + hypercholesterolemia + hypertrigliceridemia + drugs_w_loss + drugs_w_gain + mean_bp_mean + handgrip + evs_score + alcohol_dose + kcal + labs_crp + labs_alt + labs_ggt + labs_ldl + labs_triglycerides + labs_hdl + labs_quick_index, data = pha_redcap)

summary(pha_1)

plot(pha_1)
```

A modelagem estat√≠stica foi realizada por meio de modelos lineares mistos com intercepto aleat√≥rio por participante (record_id). Todas as vari√°veis cont√≠nuas foram previamente padronizadas (m√©dia = 0, desvio-padr√£o = 1), exceto o √≠ndice QUICKI, mantido em sua unidade original para fins de interpretabilidade cl√≠nica. A vari√°vel duration_difference, que representa o desvio absoluto em dias da dura√ß√£o planejada da interven√ß√£o (90 dias), foi ajustada para zero na visita basal e posteriormente padronizada. O modelo pha_2 incluiu 24 preditores fixos e foi ajustado utilizando o m√©todo de m√°xima verossimilhan√ßa restrita (REML), com inclus√£o da vari√¢ncia intraindividual no componente aleat√≥rio.

Neste modelo, observou-se que a press√£o arterial m√©dia (mean_bp_mean) foi positivamente associada ao √¢ngulo de fase (Œ≤ = 0.19, p = 0.045), sugerindo que n√≠veis mais elevados de press√£o podem estar relacionados a um melhor estado funcional da membrana celular. A dose de √°lcool (alcohol_dose) foi o preditor com maior signific√¢ncia estat√≠stica (Œ≤ = 0.25, p \< 0.001), com associa√ß√£o positiva ao √¢ngulo de fase; esse achado deve ser interpretado com cautela, pois pode refletir fatores comportamentais ou nutricionais n√£o capturados diretamente no modelo. Al√©m disso, a prote√≠na C reativa (labs_crp) apresentou associa√ß√£o positiva marginalmente significativa (Œ≤ = 0.13, p = 0.031), o que pode indicar uma complexa intera√ß√£o entre inflama√ß√£o subcl√≠nica e integridade da membrana celular.

Outros preditores como visit, allocation_group, completed_intervention, duration_difference e vari√°veis laboratoriais como labs_ldl, labs_triglycerides e labs_quick_index n√£o apresentaram associa√ß√µes estatisticamente significativas. A vari√¢ncia do intercepto aleat√≥rio por record_id permaneceu elevada (0.72), refor√ßando a relev√¢ncia da estrutura longitudinal dos dados. O crit√©rio de REML obtido foi 267.6, indicando um ajuste superior ao modelo anterior (REML = 275), e sugerindo avan√ßo na parcim√¥nia e na qualidade do modelo ap√≥s a redu√ß√£o de preditores.

**Pr√≥ximos passos sugeridos**: - Considerar remo√ß√£o de vari√°veis com p \> 0.5 e sem base te√≥rica. - Avaliar o impacto de vari√°veis correlacionadas (e.g., `bmi`, `abdomen`). - Testar modelos reduzidos orientados por AIC ou p-valor.

*Interpretation clarity* - With all predictors scaled, effect sizes are in SD units. labs_quick_index still in raw units: its coefficient = change in phase angle per unit change in QUICKI, which is very interpretable (and appropriate).

*Random effects* - You can tell that including a random intercept was appropriate by comparing the random effect variance to the residual variance. The random intercept variance for record_id is 0.6846, which represents the variability between participants. The residual variance is 0.1188, which reflects variability within participants (i.e., unexplained by the model and random noise). Now, the random intercept variance is much larger than the residual variance. This indicates that a substantial portion of the total variance in your outcome (phase_angle) is due to differences between individuals, not just random fluctuation within the same person over time. Hence, accounting for individual-level differences via a random intercept helps the model better estimate the effects of your fixed variables by controlling for this inter-individual baseline shift. Summary: Since Var(Intercept for record_id) \> Var(Residual), this suggests strong subject-level variation, meaning including (1 \| record_id) was a statistically sound choice.

### Refinements

1.  Check for multicollinearity

2.  High number of predictors (p = 30+) vs. N = 111 to your sample size. This increases risk of: Overfitting, Inflated standard errors, Instability in estimates. Suggestion: Run a stepwise reduction or penalized regression (e.g., LASSO via glmnet) to select the most stable subset.

3.  Check model fit and explained variance.

    -   Use performance::check_model() to assess residuals, normality, and homoscedasticity.
    -   Consider using marginal and conditional R¬≤ to evaluate model fit.

4.  Plot residuals and check assumptions: Homoscedasticity, Normality of residuals, Influential observations.

5.  Refine the role of visit. Currently, visit is not significant, but the study is longitudinal. So ask: Is visit best treated as a linear trend (numeric)? Would a factor with interaction be more appropriate? Would a random slope for visit help capture subject-specific trajectories?

### 1. Check for multicollinearity

Because you have many predictors (30+), and some may be redundant or highly correlated, collinearity is your first enemy. You‚Äôve handled insulin/glucose/HOMA/QUICKI well. But still check VIFs for collinearity among other variables (like BMI and abdomen, or macronutrients - total energy intake). High collinearity can: (1) Inflate standard errors (making real effects look non-significant), (2) Obscure model interpretation, (3) Affect convergence and coefficient stability. How? Use performance::check_collinearity():

```{r}
library(performance)
check_collinearity(pha_1)
# r2(pha_1)  # Marginal and conditional R¬≤
```

**Interpretation of collinearity results:** No concerning multicollinearity (all VIFs \< 3).

Variance Inflation Factor (VIF) measures how much the variance (i.e., the standard error squared) of a regression coefficient is inflated due to collinearity with other predictors. In other words, it tells you how strongly one predictor is linearly related to the others.

| **VIF Value** | **Interpretation**                             |
|---------------|------------------------------------------------|
| 1             | No correlation with other variables            |
| 1‚Äì2           | Low correlation, no concern                    |
| 2‚Äì5           | Moderate correlation ‚Äî **keep an eye**         |
| 5‚Äì10          | High correlation ‚Äî **potential problem**       |
| \>10          | Severe multicollinearity ‚Äî **likely an issue** |

### 2. Reduce the model

Your model currently includes 30 fixed effects, which may limit statistical power and interpretability due to overfitting.

A abordagem mais sensata para reduzir o modelo depende diretamente do seu objetivo principal.

Se o seu foco for **predi√ß√£o ou performance do modelo**, ent√£o a estrat√©gia **data-driven** √© mais apropriada, como:

-   **(1) Sele√ß√£o stepwise backward** com base em crit√©rios de informa√ß√£o como AIC ou BIC (AIC favorece modelos com melhor ajuste, BIC penaliza mais a complexidade).
-   **LASSO (via `glmnet`)**, que imp√µe uma penaliza√ß√£o e tende a selecionar um subconjunto est√°vel de vari√°veis, pode ser especialmente √∫til quando o n√∫mero de preditores √© alto e h√° colinearidade moderada.

Entretanto, se o objetivo for **interpreta√ß√£o e infer√™ncia causal ou explicativa** (como √© comum em ensaios cl√≠nicos e estudos de interven√ß√£o), a melhor abordagem √©:

-   **(2) Simplifica√ß√£o orientada pela teoria e plausibilidade cl√≠nica**, removendo vari√°veis que claramente n√£o contribuem de forma significativa, que se sobrep√µem a outras medidas (ex: manter apenas `quick_index` e excluir glicemia/insulina), ou que apresentem comportamento inst√°vel nos modelos (como efeitos colineares ou varia√ß√µes negativas no sinal da estimativa ao longo das vers√µes do modelo).

Quando eu menciono **"varia√ß√µes negativas no sinal da estimativa ao longo das vers√µes do modelo"**, estou me referindo ao comportamento inst√°vel dos coeficientes de algumas vari√°veis √† medida que voc√™ modifica o modelo ‚Äî por exemplo, adicionando ou removendo preditores.

Imagine que, em um modelo mais simples, a vari√°vel `bmi` tem um coeficiente **positivo**, sugerindo que quanto maior o IMC, maior o √¢ngulo de fase. Mas ao incluir outras vari√°veis correlacionadas (como `abdomen` ou `resistance`), o coeficiente de `bmi` se torna **negativo** ou **n√£o significativo**. Essa mudan√ßa de sinal pode indicar:

-   **Colinearidade**: `bmi` e `abdomen`, por exemplo, podem estar explicando o mesmo componente corporal.
-   **Falta de robustez**: a interpreta√ß√£o do efeito da vari√°vel muda conforme outras s√£o inclu√≠das, dificultando conclus√µes consistentes.
-   **Overfitting ou ajuste inst√°vel**, especialmente em amostras pequenas.

Detectar esse comportamento √© um sinal de que a vari√°vel pode estar redundante ou que h√° necessidade de ajustes ‚Äî por exemplo, usar apenas uma das vari√°veis correlacionadas ou aplicar t√©cnicas de regulariza√ß√£o.

Portanto, **"varia√ß√£o no sinal da estimativa"** n√£o √© sobre valor negativo em si, mas sobre **mudan√ßa de dire√ß√£o do efeito estimado**, o que enfraquece a confian√ßa na interpreta√ß√£o daquele preditor.

Uma boa estrat√©gia h√≠brida √©:

1.  **Fixar um conjunto m√≠nimo de vari√°veis-chave te√≥ricas** (ex: sexo, idade, grupo, tempo).
2.  **Aplicar redu√ß√£o stepwise nos demais termos**, guiando-se por BIC (se voc√™ deseja maior parcim√¥nia) ou por LASSO.
3.  **Comparar modelos com ANOVA** e gr√°ficos de res√≠duos para garantir que a simplifica√ß√£o n√£o deteriora o ajuste.

Essa abordagem permite alcan√ßar um equil√≠brio entre interpretabilidade e estabilidade do modelo.

### 3. Check model fit

A avalia√ß√£o dos pressupostos do modelo pha_1 foi realizada por meio da fun√ß√£o check_model() do pacote performance, a qual indicou que, em linhas gerais, o modelo apresenta adequa√ß√£o estat√≠stica razo√°vel. O gr√°fico de Posterior Predictive Check mostra boa sobreposi√ß√£o entre a densidade dos valores observados e os valores preditos pelo modelo, indicando adequada capacidade preditiva.

A verifica√ß√£o da linearidade dos res√≠duos frente aos valores ajustados revelou um desvio leve da horizontalidade na extremidade superior, sugerindo poss√≠vel n√£o linearidade em valores mais altos do desfecho. A homogeneidade da vari√¢ncia (homoscedasticidade) tamb√©m apresentou leve viola√ß√£o, com aumento da vari√¢ncia dos res√≠duos em valores preditos mais altos ‚Äî caracter√≠stica que pode afetar a precis√£o das estimativas nessas faixas.

A an√°lise de observa√ß√µes influentes (gr√°fico de alavancagem vs. res√≠duos padronizados) identificou algumas observa√ß√µes com leve influ√™ncia (por exemplo, IDs 10, 69, 70, 75, 109), mas nenhuma ultrapassando os limiares cl√°ssicos de alavancagem ou res√≠duos padronizados extremos.

A colinearidade foi considerada baixa, com todos os fatores de infla√ß√£o da vari√¢ncia (VIF) abaixo de 5, o que indica aus√™ncia de multicolinearidade severa entre os preditores. O gr√°fico de normalidade dos res√≠duos mostra ader√™ncia razo√°vel √† distribui√ß√£o normal, com pequenas desvios nas caudas, o que √© aceit√°vel para modelos mistos com tamanho amostral moderado. Por fim, a distribui√ß√£o dos efeitos aleat√≥rios (record_id) se aproximou da normalidade, com leve assimetria nas extremidades, refor√ßando que o intercepto aleat√≥rio foi uma escolha apropriada para capturar a variabilidade entre indiv√≠duos.

### 5. Refine the role of visit

lmer(phase_angle \~ visit + (visit \| record_id) + ...

Error: number of observations (=111) \<= number of random effects (=146) for term (visit \| record_id)

lmer(phase_angle \~ visit + (1 + visit \|\| record_id) + ...

boundary (singular) fit: see help('isSingular')

## Reduce the Model

### pha_2

```{r}
pha_2 <- lmer(phase_angle ~ (1 | record_id) + visit + allocation_group + age + sex + bmi + mean_bp_mean + handgrip + evs_score + kcal + labs_crp + labs_alt + labs_ggt + labs_ldl + labs_triglycerides + labs_hdl + labs_quick_index, data = pha_redcap)

summary(pha_2)
```

> AIC(pha_1, pha_2) df AIC pha_1 26 319.5554 pha_2 19 313.6283

> BIC(pha_1, pha_2) df BIC pha_1 26 390.0032 pha_2 19 365.1094

A compara√ß√£o entre os modelos pelo crit√©rio de informa√ß√£o de Akaike (AIC) e o crit√©rio bayesiano de informa√ß√£o (BIC) favoreceu o modelo reduzido (pha_2), que apresentou valores mais baixos de AIC (313,6 vs. 319,6) e BIC (365,1 vs. 390,0) em rela√ß√£o ao modelo completo (pha_1). Isso sugere que a simplifica√ß√£o do modelo resultou em melhor equil√≠brio entre ajuste e complexidade, mesmo com a perda de signific√¢ncia estat√≠stica de algumas covari√°veis previamente relevantes.

### pha_3

```{r}
pha_3 <- lmer(phase_angle ~ (1 | record_id) + visit + allocation_group + completed_intervention + duration_difference + age + sex + hypertension + hypercholesterolemia + hypertrigliceridemia + drugs_w_loss + drugs_w_gain + mean_bp_mean + handgrip + evs_score + alcohol_dose + kcal + labs_crp + labs_ldl + labs_quick_index, data = pha_redcap)

summary(pha_3)

check_collinearity(pha_3)

AIC(pha_1, pha_2, pha_3)
BIC(pha_1, pha_2, pha_3)

r2(pha_3)
```

```{r check-model, fig.width=10, fig.height=14}
plots <- performance::check_model(pha_3)
print(plots)
```

Tr√™s modelos hier√°rquicos foram comparados utilizando os crit√©rios de informa√ß√£o AIC e BIC. O modelo pha_3, contendo 22 preditores fixos, apresentou os menores valores de AIC (300,2) e BIC (359,8), superando tanto o modelo completo pha_1 (AIC = 319,6; BIC = 390,0) quanto o modelo reduzido pha_2 (AIC = 313,6; BIC = 365,1). Esses resultados indicam que pha_3 oferece o melhor equil√≠brio entre qualidade de ajuste e complexidade do modelo, sendo, portanto, o modelo preferido para interpreta√ß√£o final dos resultados.

Uma vers√£o reduzida do modelo foi desenvolvida com o objetivo de aprimorar o equil√≠brio entre parcim√¥nia e desempenho preditivo. A sele√ß√£o das vari√°veis foi orientada tanto por crit√©rios te√≥ricos quanto estat√≠sticos, priorizando preditores com plausibilidade cl√≠nica e contribui√ß√µes informativas nas vers√µes anteriores. O novo modelo (pha_final) manteve o intercepto aleat√≥rio por participante (record_id) e incluiu 20 preditores fixos, resultando em um crit√©rio de m√°xima verossimilhan√ßa restrita (REML) inferior ao dos modelos anteriores (REML = 256,2), indicando melhora no ajuste.

As vari√°veis mean_bp_mean (p = 0.040), alcohol_dose (p \< 0.001) e labs_crp (p = 0.035) mantiveram associa√ß√£o estatisticamente significativa com o √¢ngulo de fase, mesmo ap√≥s o ajuste multivariado, o que refor√ßa a robustez dessas associa√ß√µes. A vari√°vel visit foi mantida como efeito fixo para controle do efeito temporal, embora n√£o tenha mostrado signific√¢ncia estat√≠stica (p = 0.432). A vari√¢ncia do intercepto aleat√≥rio (œÉ¬≤ = 0.68) permaneceu relevante, o que confirma a presen√ßa de heterogeneidade entre os participantes e a adequa√ß√£o do uso de um modelo misto.

A an√°lise multicolinearidade mostrou valores de VIF \< 3 para todos os preditores, descartando problemas relevantes de colinearidade. Os diagn√≥sticos do modelo indicaram distribui√ß√£o adequada dos res√≠duos, aus√™ncia de observa√ß√µes altamente influentes e normalidade satisfat√≥ria dos efeitos aleat√≥rios, corroborando a adequa√ß√£o do modelo ajustado.

A avalia√ß√£o dos pressupostos do modelo pha_final foi realizada com base em gr√°ficos diagn√≥sticos. O gr√°fico de densidade (‚ÄúPosterior Predictive Check‚Äù) indicou que os valores preditos se alinharam adequadamente com a distribui√ß√£o observada do √¢ngulo de fase. Os res√≠duos padronizados apresentaram distribui√ß√£o aproximadamente normal, conforme demonstrado no gr√°fico de quantis te√≥ricos dos efeitos aleat√≥rios e no gr√°fico de normalidade dos res√≠duos, refor√ßando a adequa√ß√£o do modelo misto com intercepto aleat√≥rio por participante.

A homogeneidade da vari√¢ncia apresentou leve tend√™ncia de heterocedasticidade nas extremidades do ajuste, mas sem padr√£o grave de viola√ß√£o. A linearidade foi, em geral, respeitada, embora a tend√™ncia suavizada indique alguma curvatura para valores mais altos do desfecho. O gr√°fico de observa√ß√µes influentes mostrou que todos os pontos est√£o dentro dos limites de influ√™ncia padronizada, indicando aus√™ncia de outliers com alavancagem elevada.

Por fim, a an√°lise de colinearidade mostrou que todos os preditores apresentaram VIF abaixo de 3, descartando preocupa√ß√µes com multicolinearidade. Dessa forma, os pressupostos do modelo foram globalmente atendidos, validando a interpreta√ß√£o dos coeficientes estimados.

O modelo apresentou R¬≤ marginal de 0,250, indicando que as vari√°veis fixas explicam 25% da vari√¢ncia do desfecho, e R¬≤ condicional de 0,896, refletindo a alta variabilidade explicada quando se considera a estrutura aleat√≥ria intra-individual, compat√≠vel com o delineamento longitudinal do estudo.

# PCR

### 1

```{r}
model3 <- lmer(labs_crp ~ visit + allocation_group + (1 | record_id), data = data_filtered)

summary(model3)

plot(model3)  # Residuals vs. fitted

qqnorm(resid(model3)); qqline(resid(model3))  # Normality check
```

.

```{r}
model3_log <- lmer(log1p(labs_crp) ~ visit + allocation_group + (1 | record_id), data = data_filtered)
summary(model3_log)

plot(model3_log)

qqnorm(resid(model3_log)); qqline(resid(model3_log))  # Normality check
```

**log+1 transformation** to the skewed CRP variable, and the results show clear improvement.

| **Term** | **Estimate** | **p-value** | **Interpretation** |
|----------------|----------------|----------------|-------------------------|
| **Intercept** | 1.82 | \<0.001 | Mean **log(CRP + 1)** at baseline in Grupo A |
| **Visit** | ‚Äì0.099 | 0.036 | **CRP decreases significantly over time** |
| **Grupo B (vs A)** | +0.139 | 0.405 | No significant difference at baseline |

The **effect of visit became statistically significant** (p = 0.036), whereas it was borderline before (p = 0.072).

**Diagnostic Plots** **Residuals vs. Fitted**

-   More **symmetrical and homoscedastic** than before.

-   No clear fan shape or funnel ‚Äî much better than untransformed.

**Q-Q Plot**

-   **Much closer to the line**, indicating that residuals are approximately **normally distributed**.

-   A few expected mild deviations at the tails, but very acceptable.

**What does this mean in original CRP scale?**

Let‚Äôs back-transform the time effect:

-   Estimate for visit = ‚Äì0.099

-   Since you‚Äôre modeling log1p(CRP), to interpret in original scale:

$$\\text{exp}(-0.099) = 0.9056$$

This means: **each visit is associated with \~9.4% decrease** in CRP over time, **on average**.

**Summary**

| **Point**          | **Result**                                |
|--------------------|-------------------------------------------|
| Residuals          | Look better: less heteroscedasticity      |
| Q-Q plot           | Much closer to normal                     |
| Time effect        | Now statistically significant (p = 0.036) |
| Log transformation | Successfully improved model performance   |

The idea is to explore the antiinflamatory effect of the intervention. Currently, the model assumes parallel time trends for both groups, i.e., it estimates:

-   A main effect of time (CRP changes over time),

-   A main effect of group (baseline difference),

-   But no interaction (i.e., it assumes both groups change equally over time).

*Why this is not enough*

If the intervention is effective, we expect:

-   CRP to decrease faster in the intervention group (Grupo B),

-   Which means there should be a significant interaction between visit and allocation_group.

*Model with interaction:*

-   Adds visit:allocation_groupGrupo B as an interaction term,

-   Tests whether CRP changes differently over time in Grupo B vs Grupo A.

```{r}
model3_log_inter <- lmer(log1p(labs_crp) ~ visit * allocation_group + (1 | record_id), data = data_filtered)

summary(model3_log_inter)

plot(model3_log_inter)

qqnorm(resid(model3_log_inter)); qqline(resid(model3_log_inter))  # Normality check
```

Key Result: No Significant Interaction ‚Ä¢ The term visit:allocation_groupGrupo B has p = 0.620, meaning: There is no statistical evidence that the intervention led to a greater reduction in CRP over time compared to control. ‚Ä¢ The trend for CRP decrease over time is similar in both groups.

Interpretation

Despite applying a more appropriate transformation and including the interaction: ‚Ä¢ Time still shows a mild (non-significant) decreasing trend in CRP. ‚Ä¢ No baseline difference between groups. ‚Ä¢ No enhanced effect in the intervention group.

This means that, based on your data, the intervention did not show a measurable anti-inflammatory effect on CRP.

*PLOT* plot shows: ‚Ä¢ Predicted log(CRP + 1) at each visit for each group. ‚Ä¢ Makes it easy to compare time trends across intervention and control groups on the same scale used in the model. ‚Ä¢ Useful for statistical interpretation and checking for meaningful differences.

```{r}
# Create a new data frame for prediction: all combinations of visit √ó group
new_data <- expand.grid(
  visit = unique(data_filtered$visit),
  allocation_group = unique(data_filtered$allocation_group)
)

# Predict fixed effects (marginal means, no random effects)
new_data$pred_log_crp <- predict(model3_log_inter, newdata = new_data, re.form = NA)

# Plot predicted log(CRP + 1)
ggplot(new_data, aes(x = visit, y = pred_log_crp, color = allocation_group, group = allocation_group)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  labs(
    title = "Predicted CRP over Time (log scale)",
    y = "Predicted log(CRP + 1)",
    x = "Visit",
    color = "Group"
  ) +
  theme_minimal(base_size = 14)
```

*Visual Insights*

-   Both groups show a downward trend in CRP over time, suggesting a general anti-inflammatory progression.

-   Grupo B starts at a higher baseline and appears to have a slightly steeper decline in log(CRP), although the interaction term was not statistically significant (p = 0.620).

This means that although Grupo B appears to improve more, this difference in slopes is not statistically supported.

*Grupo B's Higher Baseline*

Baseline imbalance may be a concern, particularly when:

1.  The groups were supposed to be randomized and equivalent at baseline, and

2.  The outcome variable (CRP, in this case) is already higher in one group before the intervention starts.

If Grupo B starts with higher CRP, then:

-   Any greater absolute reduction over time may be due to regression to the mean, not the intervention.

-   It violates the assumption that both groups are comparable at baseline, which undermines causal inference.

*Adjust for baseline differences:*

What this model does:

-   Adjusts for baseline CRP directly, reducing bias from initial imbalance.

-   The coefficient for allocation_groupGrupo B now reflects the difference at follow-up, controlling for baseline.

-   The time effect (visit) still captures change over time.

-   The model tests whether the intervention group had lower CRP over time than expected based on their higher starting levels.

If log1p_baseline_crp is significant, it means initial inflammation strongly predicts future levels ‚Äî expected in longitudinal biomarkers.

If allocation_groupGrupo B or the visit:group interaction becomes significant after adjustment, that strengthens the case for a true treatment effect.

Let me know if you‚Äôd like to: ‚Ä¢ Visualize adjusted predictions ‚Ä¢ Back-transform to original CRP scale ‚Ä¢ Handle this in a subset of visits (e.g. only V1 and V3)

```{r}
# Adjusting for Baseline CRP in the Mixed Model (on log scale)

# Step 1: Create a baseline CRP variable (log-transformed)
# You should ensure that baseline CRP is correctly identified from your data

# Example: assuming visit 1 is baseline
data_filtered <- data_filtered %>%
  group_by(record_id) %>%
  mutate(log1p_baseline_crp = first(log1p(labs_crp[visit == 1]))) %>%
  ungroup()

# Step 2: Fit the adjusted model
model3_log_adj <- lmer(
  log1p(labs_crp) ~ visit + allocation_group + log1p_baseline_crp + (1 | record_id),
  data = data_filtered
)

# Step 3: Summarize the results
summary(model3_log_adj)
```

This model directly controls for **baseline differences in CRP**, correcting the bias introduced by the fact that **Grupo B started with higher inflammation**.

**Fixed Effects Summary**

| **Term** | **Estimate** | **p-value** | **Interpretation** |
|---------------|---------------|---------------|----------------------------|
| **(Intercept)** | 0.529 | \<0.001 | Estimated log(CRP+1) for Grupo A at baseline when baseline CRP is 0 |
| **visit** | ‚Äì0.106 | **0.015** | CRP significantly **decreases over time** |
| **Grupo B (vs Grupo A)** | ‚Äì0.008 | 0.919 | No difference between groups **after adjusting for baseline** |
| **log1p_baseline_crp** | +0.772 | \<0.001 | Strong predictor: higher baseline CRP leads to higher follow-up CRP |


**Key Takeaways**

-   **Time effect (visit) is now significant (p = 0.015)**:

    > CRP decreases over time **even after accounting for baseline**.

-   **Grupo B effect disappears (p = 0.919)**:

    > Once you adjust for baseline CRP, there‚Äôs **no evidence the intervention had a distinct effect** on CRP reduction compared to control.

-   **Baseline CRP is a major driver** of later CRP (Œ≤ = 0.77, p \< 0.001).

**Interpretation**

The original difference in CRP trends between groups was likely due to **baseline imbalance**, not the intervention itself.

This adjusted model is **more reliable**, and the results suggest:

-   CRP decreases over time for all participants,

-   But the intervention **did not produce a differential anti-inflammatory effect**.

**Dropout Influence**

```{r}
#Step 1: Check the distribution of visits per subject
# Count number of observations per subject
dropout_check <- data_filtered %>%
  group_by(record_id) %>%
  summarize(n_visits = n_distinct(visit)) %>%
  count(n_visits)


#Step 2: Compare dropout by group
## Last visit per subject
last_visit_by_group <- data_filtered %>%
  group_by(record_id, allocation_group) %>%
  summarize(last_visit = max(visit)) %>%
  ungroup()

# Table: proportion reaching visit 3
table(last_visit_by_group$allocation_group, last_visit_by_group$last_visit)
# This checks whether Grupo B had more missing data at later visits than Grupo A ‚Äî which could confound the CRP trajectory comparison.

#Step 3: Is dropout related to baseline CRP?
# If participants who dropped out had higher baseline CRP, your results may be biased due to non-random missingness (MNAR).

# Use the baseline CRP and check whether it's different in dropouts
baseline_dropout <- data_filtered %>%
  group_by(record_id) %>%
  mutate(last_visit = max(visit)) %>%
  filter(visit == 1) %>%
  mutate(dropped_out = last_visit < 3)

# Compare baseline CRP by dropout status
t.test(log1p(labs_crp) ~ dropped_out, data = baseline_dropout)
```

```         
‚Ä¢   Participants who dropped out had slightly lower CRP at baseline, but the difference is not statistically significant.
‚Ä¢   There‚Äôs no evidence that dropout was related to baseline inflammation.
‚Ä¢   Dropout appears to be random with respect to baseline CRP, which supports the Missing at Random (MAR) assumption.
```

Because: ‚Ä¢ The mixed-effects model (LMM) is valid under MAR, ‚Ä¢ There‚Äôs no significant baseline CRP difference between those who stayed and those who dropped out,

Your model results are likely unbiased with respect to dropout.

```{r}
# Back-transforming predicted log(CRP + 1) values to CRP (mg/L)

# Step 1: Create a prediction grid for all combinations of visit √ó group
# Use the median baseline CRP for prediction (in log1p scale)
baseline_crp_median <- median(log1p(baseline_dropout$labs_crp), na.rm = TRUE)

# Create grid of new data
new_data <- expand.grid(
  visit = unique(data_filtered$visit),
  allocation_group = unique(data_filtered$allocation_group)
) %>%
  mutate(log1p_baseline_crp = baseline_crp_median)

# Step 2: Predict from the adjusted model (fixed effects only)
new_data$pred_log <- predict(model3_log_adj, newdata = new_data, re.form = NA)

# Step 3: Back-transform
new_data$pred_crp <- exp(new_data$pred_log) - 1

# Step 4: Plot back-transformed predictions
ggplot(new_data, aes(x = visit, y = pred_crp, color = allocation_group, group = allocation_group)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 2.5) +
  labs(
    title = "Predicted CRP Levels Over Time (Back-Transformed)",
    x = "Visit",
    y = "Predicted CRP (mg/L)",
    color = "Group"
  ) +
  theme_minimal(base_size = 14)
```

What this plot shows

```         
‚Ä¢   Predicted CRP levels in mg/L, adjusted for the median baseline CRP.
‚Ä¢   Makes the model output clinically interpretable.
```

You can clearly see: ‚Ä¢ The overall downward trend in CRP over time. ‚Ä¢ That Grupo B does not differ from Grupo A in rate of CRP decline after adjusting for baseline.

```{r}
# add confidence intervals to predicted CRP plot (back-transformed)

# Load required packages
library(ggplot2)
library(dplyr)
library(merTools)  # for predictInterval

# Step 1: Create new data with baseline CRP held at median
baseline_crp_median <- median(log1p(baseline_dropout$labs_crp), na.rm = TRUE)

new_data <- expand.grid(
  visit = unique(data_filtered$visit),
  allocation_group = unique(data_filtered$allocation_group)
) %>%
  mutate(
    log1p_baseline_crp = baseline_crp_median,
    record_id = "dummy"  # Add a dummy ID to match model's grouping variable
  )

# Step 2: Get prediction intervals on log scale (includes uncertainty)
set.seed(123)  # for reproducibility
pred_int <- predictInterval(
  model3_log_adj,
  newdata = new_data,
  level = 0.95,
  n.sims = 1000,
  stat = "mean",
  type = "linear.prediction",
  include.resid.var = FALSE
)

# Combine with original new_data
new_data <- bind_cols(new_data, pred_int)

# Step 3: Back-transform
new_data <- new_data %>%
  mutate(
    fit = exp(fit) - 1,
    lwr = exp(lwr) - 1,
    upr = exp(upr) - 1
  )

# Step 4: Plot with ribbons (CI)
ggplot(new_data, aes(x = visit, y = fit, color = allocation_group, group = allocation_group)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 2.5) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = allocation_group), alpha = 0.2, color = NA) +
  labs(
    title = "Predicted CRP Levels with 95% CI (Back-Transformed)",
    y = "Predicted CRP (mg/L)",
    x = "Visit",
    color = "Group",
    fill = "Group"
  ) +
  theme_minimal(base_size = 14)
```

```{r}
# Optional: Line plot of individual trajectories
ggplot(data_filtered, aes(x = visit, y = labs_crp, group = record_id, color = allocation_group)) +
  geom_line(alpha = 0.3) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Individual CRP Trajectories (Raw Data)",
    y = "Observed CRP (mg/L)",
    x = "Visit",
    color = "Group"
  ) +
  theme_minimal(base_size = 14)
```

### 2

```{r}
data_filtered_lmm <- data_filtered %>%
  group_by(record_id) %>%
  filter(n() > 1) %>%
  ungroup()

model4_log <- lmer(log1p(labs_crp) ~ visit + bmi + age + sex + dass_score_stress + 
     labs_hba1c + labs_ggt + labs_triglycerides + allocation_group + 
     (1 | record_id), data = data_filtered_lmm)

summary(model4_log)

plot(model3_log)

qqnorm(resid(model3_log)); qqline(resid(model3_log))  # Normality check```
```
