---
title: "Main outcomes"
author: "S.P.L.M., Gustavo"
date: today
format:
  html:
    toc: true
    toc-depth: 2
    toc-float:
      collapsed: false
      smooth-scroll: true
  pdf:
    toc: true
    toc-depth: 2
    pdf-engine: xelatex
---

```{r}
rm(list = ls())
graphics.off()
cat("\014")  # Clear any pending RStudio sessions or temporary files

# Load functions from external script
source("helper_functions.R")

## Load necessary libraries
library(tidyverse)
library(readxl)
library(lubridate)
library(stringr)
library(purrr)
library(here)
library(lme4)
library(lmerTest)
library(skimr)

# Read Files ----
## Codebooks
codebook_dvep <- read_excel(
    "Codebooks/codebook_dvep.xlsx",
    col_names = TRUE,
    col_types = NULL,
    na = c("", "NA", "NI", "UNK", "NASK", "ASKU", "INV"),
    trim_ws = TRUE,
    skip = 0, # Number of lines to skip before reading data
    n_max = Inf, # Maximum number of lines to read.
    guess_max = 1000
) %>%
    arrange(index)

codebook_structure  <- read_csv(
    "Codebooks/codebook_structure.csv",
    col_names = TRUE)

codebook_ncit  <- read_csv(
    "Codebooks/codebook_ncit.csv",
    col_names = TRUE)

codebook_bia <- read_excel(
    "Codebooks/codebook_bia.xlsx",
    col_names = TRUE,
    col_types = NULL,
    na = c("", "NA", "NI", "UNK", "NASK", "ASKU", "INV"),
    trim_ws = TRUE,
    skip = 0, # Number of lines to skip before reading data
    n_max = Inf, # Maximum number of lines to read.
    guess_max = 1000
) %>%
    arrange(index)

## Data
data <- readRDS("Data_processed/data.rds")
data_bia <- readRDS("Data_processed/data_bia.rds")
data_bia_D1 <- readRDS("Data_processed/data_bia_D1.rds")
data_bia_D1_mean <- readRDS("Data_processed/data_bia_D1_mean.rds")
data_bia_D1_raw <- readRDS("Data_processed/data_bia_D1_raw.rds")
data_bia_D3 <- readRDS("Data_processed/data_bia_D3.rds")
data_bia_D3_mean <- readRDS("Data_processed/data_bia_D3_mean.rds")
data_bia_D3_raw <- readRDS("Data_processed/data_bia_D3_raw.rds")
data_bia_mean <- readRDS("Data_processed/data_bia_mean.rds")
data_d1_exclusive <- readRDS("Data_processed/data_d1_exclusive.rds")
data_filtered <- readRDS("Data_processed/data_filtered.rds")
data_filtered_seca <- readRDS("Data_processed/data_filtered_seca.rds")
I21_conditions_R <- readRDS("Data_processed/I21_conditions_R.rds")
I22_drugs_R <- readRDS("Data_processed/I22_drugs_R.rds")
I27_labs_R <- readRDS("Data_processed/I27_labs_R.rds")
I29_compliance <- readRDS("Data_processed/I29_compliance.rds")
I30_events_R <- readRDS("Data_processed/I30_events_R.rds")

## SUPERTIBBLE
data_instruments <- readRDS("Data_instruments/data_instruments.rds")
```

# Variáveis de interesse

(1 \| record_id) + visit + allocation_group + age + sex + race + education +

```         
# Comorbidities #
```

hypertension + hypercholesterolemia + hypertrigliceridemia + insulin + drugs_w_loss + drugs_w_gain +

```         
# Anthro
```

abdomen + bmi + mean_bp_mean

```         
# Questionnaires #
```

whoqol_score_overall + ecap_score + evs_score + dass_score_stress + dass_score_anxiety + dass_score_depression + alcohol_significant + smoke_history + carbs_kcal + protein_kcal + fat_kcal + drugs_dose_change_yn +

```         
# Adesão #
```

completed_intervention, intervention_duration, education_years? cp_taking_as_directed_yn, cp_missed_dose_yn, cp_missed_dose_count, cp_discontinued_yn, cp_discontinued_n_days, cp_ran_out_of_drug_yn, cp_medication_confidence_sca

# Adesão

These variables are related to the compliance to the drug intervention.

| variable | label | field type | options |
|--------------|--------------|--------------|-------------------------------|
| cp_taking_as_directed_yn | Está tomando conforme orientado? | radio | 0, Não ; 1, Sim |
| cp_schedule | Cronograma de medicação | dropdown | 1, conforme orientado ; 2, 6 cp/d, em outros horários ; 3, 3 cápsulas ao dia (1 cápsula com café da manhã, 1 com almoço e 1 com o jantar) ; 4, 3 cápsulas ao dia, em outros horários ; 5, Outros (especifique) |
| cp_schedule_other | Outra forma de tomar (especifique) | text |  |
| cp_reminder | Método de lembrete para medicamento | dropdown | 1, Alarme no celular ; 2, Caixa de remédios com divisórias para cada horário ; 3, Lembrete escrito em um calendário ; 4, Outro (especificar) |
| cp_reminder_other | Outro lembrete (especifique) | text |  |
| cp_missed_dose_yn | Perdeu alguma dose? | radio | 0, Não ; 1, Sim |
| cp_missed_dose_count | Quantas doses perdidas? | dropdown | 1, 1 vez ; 2, 2 vezes ; 3, 3 a 5 vezes ; 4, 5 a 10 vezes ; 5, mais de 10 vezes |
| cp_missed_dose_timing | Momentos de doses perdidas | dropdown | 1, Com o café da manhã ; 2, Com o almoço ; 3, Com o jantar ; 4, Outro (especificar) |
| cp_missed_dose_timing_other | Outros momentos de doses perdidas | text |  |
| cp_discontinued_yn | Parou de tomar o medicamento? | radio | 0, Não ; 1, Sim |
| cp_discontinued_n_days | Dias de interrupção | dropdown | 1, 1 dia ; 2, 2 dias ; 3, 3 a 5 dias ; 4, 5 a 10 dias ; 5, mais de 10 dias |
| cp_discontinued_reason | Motivo da interrupção | dropdown | 1, Efeito colateral ; 2, Esquecimento ; 3, Dificuldade em seguir horários ; 4, Outro (especificar) |
| cp_discontinued_reason_other | Outra razão (especificar) | notes |  |
| cp_ran_out_of_drug_yn | Ficou sem medicamento? | radio | 0, Não ; 1, Sim |
| cp_ran_out_reason | Motivo de falta de medicamento | notes |  |
| cp_daily_routine_change_medication_adherence_yn | Mudança de rotina afeta adesão ao medicamento? | radio | 0, Não ; 1, Sim |
| cp_daily_routine_change_specify | Especificar mudança na rotina | notes |  |
| cp_perceived_improvement_yn | Percebeu melhorias? | radio | 0, Não ; 1, Sim |
| cp_perceived_improvement | Melhorias relatadas | notes |  |
| cp_challenges_taking_yn | Dificuldades com medicação? | radio | 0, Não ; 1, Sim |
| cp_challenges_taking | Desafios na adesão ao medicamento | notes |  |
| cp_medication_confidence_scale | Confiança no cronograma (1-10) | slider | Nada confiante ; Neutro ; Totalmente confiante |
| cp_self_reported_compliance_rate | Adesão ao medicamento | radio | 1, Ruim ; 2, Regular ; 3, Boa ; 4, Excelente |

# Correcting values

```{r}

# Correcting values --------
I29_compliance_new <- I29_compliance %>%
    select(
        record_id, visit, cp_taking_as_directed_yn:cp_self_reported_compliance_rate
    ) %>% 
    left_join(
        data_filtered %>% 
            select(record_id, visit, completed_intervention, intervention_duration),
        by = c("record_id", "visit")
    )

#I29_compliance_new %>% glimpse()
#I29_compliance_new %>% skimr::skim()


I29_compliance_new <- I29_compliance_new %>%
  mutate(
    cp_taking_as_directed_yn = case_when(
      record_id == 12 & visit == 3 ~ "Não",
      record_id == 22 & visit == 3 ~ "Não",
      record_id == 27 & visit == 2 ~ "Não",
      record_id == 36 & visit == 2 ~ "Não",
      record_id == 56 & visit == 2 ~ "Não",
      record_id == 67 & visit == 2 ~ "Não",
      TRUE                        ~ cp_taking_as_directed_yn
    ),
    cp_schedule = case_when(
      record_id == 72 & visit == 2 ~ "3 cápsulas uma vez ao dia",
      record_id == 67 & visit == 2 ~ "6 cp/d, em outros horários",
      TRUE                        ~ cp_schedule
    ),
    cp_missed_dose_yn = case_when(
      record_id == 56 & visit == 2 ~ "Não",
      TRUE                        ~ cp_missed_dose_yn
    ),
    cp_discontinued_n_days = case_when(
      record_id == 23 & visit == 3 ~ "5 a 10 dias",
      record_id == 31 & visit == 2 ~ "3 a 5 dias",
      record_id == 38 & visit == 3 ~ "5 a 10 dias",
      record_id == 41 & visit == 2 ~ "5 a 10 dias",
      record_id == 50 & visit == 2 ~ "3 a 5 dias",
      record_id == 54 & visit == 3 ~ "5 a 10 dias",
      record_id == 56 & visit == 2 ~ "mais de 10 dias",
      record_id == 72 & visit == 3 ~ "mais de 10 dias", 
      TRUE                        ~ cp_discontinued_n_days
    )
  )
```

# Simplifying tibble

```{r}
I29_compliance_new <- I29_compliance_new %>%
  mutate(
    cp_missed_dose_count = if_else(is.na(cp_missed_dose_count), "Não", cp_missed_dose_count),
    cp_discontinued_n_days = if_else(is.na(cp_discontinued_n_days), "Não", cp_discontinued_n_days),
  ) %>% 
    select(
        record_id, visit, completed_intervention, intervention_duration, 
        cp_schedule, cp_missed_dose_count, cp_discontinued_n_days,
        cp_ran_out_of_drug_yn,
        cp_medication_confidence_scale, cp_self_reported_compliance_rate)
```

# Escore composto de adesão (`compliance_score_visit`)

```{r}
# mapeamentos em vetores nomeados
schedule_scale <- c(
  "conforme orientado"                                       = 1,
  "6 cp/d, em outros horários"                               = 0.75,
  "3 cápsulas ao dia (1 cápsula com café da manhã, 1 com almoço e 1 com o jantar)" = 0.5,
  "3 cápsulas ao dia, em outros horários"                    = 0.50,
  "Outros (especifique)"                                     = 0        # zera o escore
)

missed_scale <- c(
  "Não"                 = 1,
  "1 vez"               = 0.80,
  "2 vezes"             = 0.60,
  "3 a 5 vezes"         = 0.40,
  "5 a 10 vezes"        = 0.20,
  "mais de 10 vezes"    = 0
)

discont_scale <- c(
  "Não"                 = 1,
  "1 dia"               = 0.80,
  "2 dias"              = 0.60,
  "3 a 5 dias"          = 0.40,
  "5 a 10 dias"         = 0.20,
  "mais de 10 dias"     = 0
)

rate_scale <- c(
  "Excelente" = 1,
  "Boa"       = 0.75,
  "Regular"   = 0.50,
  "Ruim"      = 0.25
)

I29_compliance_new <- I29_compliance_new %>% 
  mutate(
    # Cronograma
    pts_schedule = schedule_scale[cp_schedule] %>% unname(),
    
    # Perda de doses
    pts_missed   = missed_scale[cp_missed_dose_count] %>% unname(),
    
    # Interrupção
    pts_discont  = discont_scale[cp_discontinued_n_days] %>% unname(),
    
    # Ficou sem medicamento
    pts_ranout   = case_when(
      cp_ran_out_of_drug_yn == "Não" ~ 1,
      cp_ran_out_of_drug_yn == "Sim" ~ 0,
      TRUE                           ~ NA_real_
    ),
    
    # Confiança (somente visita 2)
    pts_conf     = cp_medication_confidence_scale / 10,
    
    # Autoavaliação
    pts_selfrate = rate_scale[cp_self_reported_compliance_rate] %>% unname()
  ) %>% 
  
    
    # Soma por visita com atribuição de peso
  rowwise() %>% 
  mutate(
    total_pts   = sum(c_across(starts_with("pts_")), na.rm = TRUE),
    domains_ok  = sum(!is.na(c_across(starts_with("pts_")))),
    compliance_score_visit = total_pts / domains_ok
  ) %>% 
  ungroup()

### If cp_schedule == Outros (especifique), the final score for that visit should be zero

I29_compliance_new <- I29_compliance_new %>% 
mutate(
    compliance_score_visit = if_else(
      cp_schedule == "Outros (especifique)",
      0,
      compliance_score_visit
    )
  )

# (opcional) média de adesão por participante
#compliance_by_id <- I29_compliance_new %>% 
#  group_by(record_id) %>% 
#  summarise(compliance_score_mean = mean(compliance_score_visit, na.rm = TRUE))
```

Converte cada variável em pontos padronizados (0 – 1), soma os pontos obtidos na visita e divide pelo número de domínios válidos.\
O resultado é um escore contínuo de 0 (pior adesão) a 1 (melhor adesão).

**Regras de pontuação**

| Domínio | Variável | Regra → Pontos |
|----------------|----------------|-----------------------------------------|
| **Cronograma** | `cp_schedule` | “conforme orientado” → 1<br>“6 cp/d, em outros horários” → 0.75<br>“3 cápsulas / horário orientado” → 0.75<br>“3 cápsulas / outros horários” → 0.50<br>“Outros (especifique)” → 0 |
| **Perda de doses – YN** | `cp_missed_dose_count`<br>(valor “Não”) | “Não” → 1 |
| **Perda de doses – quantas** | `cp_missed_dose_count` | “1 vez” → 0.80<br>“2 vezes” → 0.60<br>“3 a 5 vezes” → 0.40<br>“5 a 10 vezes” → 0.20<br>“mais de 10 vezes” → 0 |
| **Interrupção – YN** | `cp_discontinued_n_days`<br>(valor “Não”) | “Não” → 1 |
| **Interrupção – dias** | `cp_discontinued_n_days` | “1 dia” → 0.80<br>“2 dias” → 0.60<br>“3 a 5 dias” → 0.40<br>“5 a 10 dias” → 0.20<br>“mais de 10 dias” → 0 |
| **Ficou sem medicamento** | `cp_ran_out_of_drug_yn` | Não → 1 · Sim → 0 |
| **Confiança (1-10)** | `cp_medication_confidence_scale` | escala ÷ 10 (8 → 0.8) |
| **Autoavaliada** | `cp_self_reported_compliance_rate` | Excelente → 1 · Boa → 0.75 · Regular → 0.50 · Ruim → 0.25 |

*Se o valor for **NA**, o domínio não entra no denominador (não penaliza).*

# Intervention_duration

```{r}
I29_compliance_new <- I29_compliance_new %>% 
    mutate(
        duration_deviation = intervention_duration - 90, # diferença bruta (neg = menos dias)
        duration_difference = abs(duration_deviation) # desvio absoluto (pior quanto maior)
        )
```

# Incorporate compliance into data_filtered

```{r}
data_filtered <- data_filtered %>% 
    left_join(
        I29_compliance_new %>% 
            select(record_id, visit, compliance_score_visit, duration_difference),
        by = c("record_id", "visit")
    ) %>% 
    
    group_by(record_id) %>% # Set baseline compliance to 1
    ungroup() %>%
    
    select(
     record_id, visit, allocation_group, 
     completed_intervention, compliance_score_visit, duration_difference,
     age:light_clothes_yn,
     dplyr::starts_with("labs_")
    ) %>% 
    mutate(
        alcohol_dose = if_else(is.na(alcohol_dose), 0, alcohol_dose),
        kcal = carbs_kcal + protein_kcal + fat_kcal,
    )
```

# Set duration_difference to 0 for visit 1

```{r}
data_filtered <- data_filtered %>% 
    mutate(
        duration_difference = if_else(visit == 1, 0, duration_difference)
    )
```

# Replace NAs for visit 2 with data from visit 1

```{r, eval=FALSE}
vars_to_fill <- c("alcohol_significant", "alcohol_dose", "smoke_history", "pack_years", "whoqol_score_overall", "ecap_score", "alcohol_significant", "dass_score_stress", "dass_score_anxiety", "dass_score_depression", "resistance", "reactance", "phase_angle", "handgrip", )

data <- data %>%
  arrange(record_id, visit) %>%
  group_by(record_id) %>%
  mutate(across(all_of(vars_to_fill), ~ if_else(
    visit == 2 & is.na(.x),
    .x[visit == 1],
    .x
  ))) %>%
  ungroup()
```

# REDUCE TIBBLE FOR MODELLING

```{r}
data_model <- data_filtered %>% 
    select(
        record_id:sex,
        hypertension:ecap_score,
        abdomen, bmi, mean_bp_mean,
        resistance:evs_score,
        alcohol_dose, 
        carbs_kcal, protein_kcal, fat_kcal, kcal,
        labs_crp:labs_alkp,
        labs_cholesterol:labs_quick_index
    )

saveRDS(
    data_model,
    "Data_processed/data_model.rds")

vars_to_keep <- names(data_model)

# Step 2: filter codebook_dvep
codebook_data_model <- codebook_dvep %>%
    filter(variable %in% vars_to_keep) %>% 
    select(
        variable, label_pt, field_type, choices)

saveRDS(
    codebook_data_model,
    "Data_processed/codebook_data_model.rds")
```

# SCALING

$${QUICKI} = \frac{1}{\\log(insulin) + log(glucose)}$$

$$
HOMA-IR = \frac{insulin * glucose}{405}
$$

```{r}
data_model_scaled <- data_model %>%
  mutate(across(
    .cols = c(
        duration_difference, age,
        whoqol_score_overall, dass_score_depression, dass_score_anxiety,
        dass_score_stress, ecap_score, 
        abdomen, bmi, mean_bp_mean,
        resistance, reactance, 
        handgrip, evs_score, alcohol_dose,
        carbs_kcal, protein_kcal, fat_kcal, kcal,
        labs_crp, labs_ast, labs_alt, labs_ggt, labs_alkp,
        labs_cholesterol, labs_ldl, labs_hba1c, labs_triglycerides,
        labs_hdl, labs_glucose, labs_insulin, labs_homa_ir
    ),
    .fns = ~ as.numeric(scale(.))
  ))

scaling_params <- data_model %>%
  summarise(across(
    .cols = c(
      duration_difference, age,
      whoqol_score_overall, dass_score_depression, dass_score_anxiety,
      dass_score_stress, ecap_score, 
      abdomen, bmi, mean_bp_mean,
      resistance, reactance, 
      handgrip, evs_score, alcohol_dose,
      carbs_kcal, protein_kcal, fat_kcal,
      labs_crp, labs_ast, labs_alt, labs_ggt, labs_alkp,
      labs_cholesterol, labs_ldl, labs_hba1c, labs_triglycerides,
      labs_hdl, labs_glucose, labs_insulin, labs_homa_ir
    ),
    list(mean = ~mean(., na.rm = TRUE), sd = ~sd(., na.rm = TRUE))
  )) %>%
  pivot_longer(everything(),
               names_to = c("variable", ".value"),
               names_sep = "_(?=[^_]+$)",  # 👈 this fixes the splitting
               names_transform = list(.value = as.character))
```

```{r, eval=FALSE}
# THEN, FOR NEW DATA
scale_with_params <- function(new_data, params) {
  for (i in seq_len(nrow(params))) {
    var <- params$variable[i]
    mean_val <- params$mean[i]
    sd_val <- params$sd[i]
    if (var %in% names(new_data)) {
      new_data[[var]] <- (new_data[[var]] - mean_val) / sd_val
    }
  }
  return(new_data)
}

new_data_scaled <- scale_with_params(new_data, scaling_params)
```

# ÂNGULO DE FASE

Filtrando D1 and D3

```{r}
pha_redcap <- data_model_scaled %>% 
    filter(
        visit %in% c(1, 3)
    ) %>% 
    mutate(
        compliance_score_visit = case_when(
            visit == 3 & completed_intervention == "Não" ~ 0,
            TRUE ~ compliance_score_visit
        )
    )
```

## All variables

```{r}
library(lme4)
library(lmerTest) # Adds p-values to summary()
```

```{r}
pha_1 <- lmer(phase_angle ~ (1 | record_id) + visit + allocation_group + completed_intervention + duration_difference + age + sex + hypertension + hypercholesterolemia + hypertrigliceridemia + drugs_w_loss + drugs_w_gain + mean_bp_mean + handgrip + evs_score + alcohol_dose + kcal + labs_crp + labs_alt + labs_ggt + labs_ldl + labs_triglycerides + labs_hdl + labs_quick_index, data = pha_redcap)

summary(pha_1)

plot(pha_1)
```

A modelagem estatística foi realizada por meio de modelos lineares mistos com intercepto aleatório por participante (record_id). Todas as variáveis contínuas foram previamente padronizadas (média = 0, desvio-padrão = 1), exceto o índice QUICKI, mantido em sua unidade original para fins de interpretabilidade clínica. A variável duration_difference, que representa o desvio absoluto em dias da duração planejada da intervenção (90 dias), foi ajustada para zero na visita basal e posteriormente padronizada. O modelo pha_2 incluiu 24 preditores fixos e foi ajustado utilizando o método de máxima verossimilhança restrita (REML), com inclusão da variância intraindividual no componente aleatório.

Neste modelo, observou-se que a pressão arterial média (mean_bp_mean) foi positivamente associada ao ângulo de fase (β = 0.19, p = 0.045), sugerindo que níveis mais elevados de pressão podem estar relacionados a um melhor estado funcional da membrana celular. A dose de álcool (alcohol_dose) foi o preditor com maior significância estatística (β = 0.25, p \< 0.001), com associação positiva ao ângulo de fase; esse achado deve ser interpretado com cautela, pois pode refletir fatores comportamentais ou nutricionais não capturados diretamente no modelo. Além disso, a proteína C reativa (labs_crp) apresentou associação positiva marginalmente significativa (β = 0.13, p = 0.031), o que pode indicar uma complexa interação entre inflamação subclínica e integridade da membrana celular.

Outros preditores como visit, allocation_group, completed_intervention, duration_difference e variáveis laboratoriais como labs_ldl, labs_triglycerides e labs_quick_index não apresentaram associações estatisticamente significativas. A variância do intercepto aleatório por record_id permaneceu elevada (0.72), reforçando a relevância da estrutura longitudinal dos dados. O critério de REML obtido foi 267.6, indicando um ajuste superior ao modelo anterior (REML = 275), e sugerindo avanço na parcimônia e na qualidade do modelo após a redução de preditores.

**Próximos passos sugeridos**: - Considerar remoção de variáveis com p \> 0.5 e sem base teórica. - Avaliar o impacto de variáveis correlacionadas (e.g., `bmi`, `abdomen`). - Testar modelos reduzidos orientados por AIC ou p-valor.

*Interpretation clarity* - With all predictors scaled, effect sizes are in SD units. labs_quick_index still in raw units: its coefficient = change in phase angle per unit change in QUICKI, which is very interpretable (and appropriate).

*Random effects* - You can tell that including a random intercept was appropriate by comparing the random effect variance to the residual variance. The random intercept variance for record_id is 0.6846, which represents the variability between participants. The residual variance is 0.1188, which reflects variability within participants (i.e., unexplained by the model and random noise). Now, the random intercept variance is much larger than the residual variance. This indicates that a substantial portion of the total variance in your outcome (phase_angle) is due to differences between individuals, not just random fluctuation within the same person over time. Hence, accounting for individual-level differences via a random intercept helps the model better estimate the effects of your fixed variables by controlling for this inter-individual baseline shift. Summary: Since Var(Intercept for record_id) \> Var(Residual), this suggests strong subject-level variation, meaning including (1 \| record_id) was a statistically sound choice.

### Refinements

1.  Check for multicollinearity

2.  High number of predictors (p = 30+) vs. N = 111 to your sample size. This increases risk of: Overfitting, Inflated standard errors, Instability in estimates. Suggestion: Run a stepwise reduction or penalized regression (e.g., LASSO via glmnet) to select the most stable subset.

3.  Check model fit and explained variance.

    -   Use performance::check_model() to assess residuals, normality, and homoscedasticity.
    -   Consider using marginal and conditional R² to evaluate model fit.

4.  Plot residuals and check assumptions: Homoscedasticity, Normality of residuals, Influential observations.

5.  Refine the role of visit. Currently, visit is not significant, but the study is longitudinal. So ask: Is visit best treated as a linear trend (numeric)? Would a factor with interaction be more appropriate? Would a random slope for visit help capture subject-specific trajectories?

### 1. Check for multicollinearity

Because you have many predictors (30+), and some may be redundant or highly correlated, collinearity is your first enemy. You’ve handled insulin/glucose/HOMA/QUICKI well. But still check VIFs for collinearity among other variables (like BMI and abdomen, or macronutrients - total energy intake). High collinearity can: (1) Inflate standard errors (making real effects look non-significant), (2) Obscure model interpretation, (3) Affect convergence and coefficient stability. How? Use performance::check_collinearity():

```{r}
library(performance)
check_collinearity(pha_1)
# r2(pha_1)  # Marginal and conditional R²
```

**Interpretation of collinearity results:** No concerning multicollinearity (all VIFs \< 3).

Variance Inflation Factor (VIF) measures how much the variance (i.e., the standard error squared) of a regression coefficient is inflated due to collinearity with other predictors. In other words, it tells you how strongly one predictor is linearly related to the others.

| **VIF Value** | **Interpretation**                             |
|---------------|------------------------------------------------|
| 1             | No correlation with other variables            |
| 1–2           | Low correlation, no concern                    |
| 2–5           | Moderate correlation — **keep an eye**         |
| 5–10          | High correlation — **potential problem**       |
| \>10          | Severe multicollinearity — **likely an issue** |

### 2. Reduce the model

Your model currently includes 30 fixed effects, which may limit statistical power and interpretability due to overfitting.

A abordagem mais sensata para reduzir o modelo depende diretamente do seu objetivo principal.

Se o seu foco for **predição ou performance do modelo**, então a estratégia **data-driven** é mais apropriada, como:

-   **(1) Seleção stepwise backward** com base em critérios de informação como AIC ou BIC (AIC favorece modelos com melhor ajuste, BIC penaliza mais a complexidade).
-   **LASSO (via `glmnet`)**, que impõe uma penalização e tende a selecionar um subconjunto estável de variáveis, pode ser especialmente útil quando o número de preditores é alto e há colinearidade moderada.

Entretanto, se o objetivo for **interpretação e inferência causal ou explicativa** (como é comum em ensaios clínicos e estudos de intervenção), a melhor abordagem é:

-   **(2) Simplificação orientada pela teoria e plausibilidade clínica**, removendo variáveis que claramente não contribuem de forma significativa, que se sobrepõem a outras medidas (ex: manter apenas `quick_index` e excluir glicemia/insulina), ou que apresentem comportamento instável nos modelos (como efeitos colineares ou variações negativas no sinal da estimativa ao longo das versões do modelo).

Quando eu menciono **"variações negativas no sinal da estimativa ao longo das versões do modelo"**, estou me referindo ao comportamento instável dos coeficientes de algumas variáveis à medida que você modifica o modelo — por exemplo, adicionando ou removendo preditores.

Imagine que, em um modelo mais simples, a variável `bmi` tem um coeficiente **positivo**, sugerindo que quanto maior o IMC, maior o ângulo de fase. Mas ao incluir outras variáveis correlacionadas (como `abdomen` ou `resistance`), o coeficiente de `bmi` se torna **negativo** ou **não significativo**. Essa mudança de sinal pode indicar:

-   **Colinearidade**: `bmi` e `abdomen`, por exemplo, podem estar explicando o mesmo componente corporal.
-   **Falta de robustez**: a interpretação do efeito da variável muda conforme outras são incluídas, dificultando conclusões consistentes.
-   **Overfitting ou ajuste instável**, especialmente em amostras pequenas.

Detectar esse comportamento é um sinal de que a variável pode estar redundante ou que há necessidade de ajustes — por exemplo, usar apenas uma das variáveis correlacionadas ou aplicar técnicas de regularização.

Portanto, **"variação no sinal da estimativa"** não é sobre valor negativo em si, mas sobre **mudança de direção do efeito estimado**, o que enfraquece a confiança na interpretação daquele preditor.

Uma boa estratégia híbrida é:

1.  **Fixar um conjunto mínimo de variáveis-chave teóricas** (ex: sexo, idade, grupo, tempo).
2.  **Aplicar redução stepwise nos demais termos**, guiando-se por BIC (se você deseja maior parcimônia) ou por LASSO.
3.  **Comparar modelos com ANOVA** e gráficos de resíduos para garantir que a simplificação não deteriora o ajuste.

Essa abordagem permite alcançar um equilíbrio entre interpretabilidade e estabilidade do modelo.

### 3. Check model fit

A avaliação dos pressupostos do modelo pha_1 foi realizada por meio da função check_model() do pacote performance, a qual indicou que, em linhas gerais, o modelo apresenta adequação estatística razoável. O gráfico de Posterior Predictive Check mostra boa sobreposição entre a densidade dos valores observados e os valores preditos pelo modelo, indicando adequada capacidade preditiva.

A verificação da linearidade dos resíduos frente aos valores ajustados revelou um desvio leve da horizontalidade na extremidade superior, sugerindo possível não linearidade em valores mais altos do desfecho. A homogeneidade da variância (homoscedasticidade) também apresentou leve violação, com aumento da variância dos resíduos em valores preditos mais altos — característica que pode afetar a precisão das estimativas nessas faixas.

A análise de observações influentes (gráfico de alavancagem vs. resíduos padronizados) identificou algumas observações com leve influência (por exemplo, IDs 10, 69, 70, 75, 109), mas nenhuma ultrapassando os limiares clássicos de alavancagem ou resíduos padronizados extremos.

A colinearidade foi considerada baixa, com todos os fatores de inflação da variância (VIF) abaixo de 5, o que indica ausência de multicolinearidade severa entre os preditores. O gráfico de normalidade dos resíduos mostra aderência razoável à distribuição normal, com pequenas desvios nas caudas, o que é aceitável para modelos mistos com tamanho amostral moderado. Por fim, a distribuição dos efeitos aleatórios (record_id) se aproximou da normalidade, com leve assimetria nas extremidades, reforçando que o intercepto aleatório foi uma escolha apropriada para capturar a variabilidade entre indivíduos.

### 5. Refine the role of visit

lmer(phase_angle \~ visit + (visit \| record_id) + ...

Error: number of observations (=111) \<= number of random effects (=146) for term (visit \| record_id)

lmer(phase_angle \~ visit + (1 + visit \|\| record_id) + ...

boundary (singular) fit: see help('isSingular')

## Reduce the Model

### pha_2

```{r}
pha_2 <- lmer(phase_angle ~ (1 | record_id) + visit + allocation_group + age + sex + bmi + mean_bp_mean + handgrip + evs_score + kcal + labs_crp + labs_alt + labs_ggt + labs_ldl + labs_triglycerides + labs_hdl + labs_quick_index, data = pha_redcap)

summary(pha_2)
```

> AIC(pha_1, pha_2) df AIC pha_1 26 319.5554 pha_2 19 313.6283

> BIC(pha_1, pha_2) df BIC pha_1 26 390.0032 pha_2 19 365.1094

A comparação entre os modelos pelo critério de informação de Akaike (AIC) e o critério bayesiano de informação (BIC) favoreceu o modelo reduzido (pha_2), que apresentou valores mais baixos de AIC (313,6 vs. 319,6) e BIC (365,1 vs. 390,0) em relação ao modelo completo (pha_1). Isso sugere que a simplificação do modelo resultou em melhor equilíbrio entre ajuste e complexidade, mesmo com a perda de significância estatística de algumas covariáveis previamente relevantes.

### pha_3

```{r}
pha_3 <- lmer(phase_angle ~ (1 | record_id) + visit + allocation_group + completed_intervention + duration_difference + age + sex + hypertension + hypercholesterolemia + hypertrigliceridemia + drugs_w_loss + drugs_w_gain + mean_bp_mean + handgrip + evs_score + alcohol_dose + kcal + labs_crp + labs_ldl + labs_quick_index, data = pha_redcap)

summary(pha_3)

check_collinearity(pha_3)

AIC(pha_1, pha_2, pha_3)
BIC(pha_1, pha_2, pha_3)

r2(pha_3)
```

```{r check-model, fig.width=10, fig.height=14}
plots <- performance::check_model(pha_3)
print(plots)
```

Três modelos hierárquicos foram comparados utilizando os critérios de informação AIC e BIC. O modelo pha_3, contendo 22 preditores fixos, apresentou os menores valores de AIC (300,2) e BIC (359,8), superando tanto o modelo completo pha_1 (AIC = 319,6; BIC = 390,0) quanto o modelo reduzido pha_2 (AIC = 313,6; BIC = 365,1). Esses resultados indicam que pha_3 oferece o melhor equilíbrio entre qualidade de ajuste e complexidade do modelo, sendo, portanto, o modelo preferido para interpretação final dos resultados.

Uma versão reduzida do modelo foi desenvolvida com o objetivo de aprimorar o equilíbrio entre parcimônia e desempenho preditivo. A seleção das variáveis foi orientada tanto por critérios teóricos quanto estatísticos, priorizando preditores com plausibilidade clínica e contribuições informativas nas versões anteriores. O novo modelo (pha_final) manteve o intercepto aleatório por participante (record_id) e incluiu 20 preditores fixos, resultando em um critério de máxima verossimilhança restrita (REML) inferior ao dos modelos anteriores (REML = 256,2), indicando melhora no ajuste.

As variáveis mean_bp_mean (p = 0.040), alcohol_dose (p \< 0.001) e labs_crp (p = 0.035) mantiveram associação estatisticamente significativa com o ângulo de fase, mesmo após o ajuste multivariado, o que reforça a robustez dessas associações. A variável visit foi mantida como efeito fixo para controle do efeito temporal, embora não tenha mostrado significância estatística (p = 0.432). A variância do intercepto aleatório (σ² = 0.68) permaneceu relevante, o que confirma a presença de heterogeneidade entre os participantes e a adequação do uso de um modelo misto.

A análise multicolinearidade mostrou valores de VIF \< 3 para todos os preditores, descartando problemas relevantes de colinearidade. Os diagnósticos do modelo indicaram distribuição adequada dos resíduos, ausência de observações altamente influentes e normalidade satisfatória dos efeitos aleatórios, corroborando a adequação do modelo ajustado.

A avaliação dos pressupostos do modelo pha_final foi realizada com base em gráficos diagnósticos. O gráfico de densidade (“Posterior Predictive Check”) indicou que os valores preditos se alinharam adequadamente com a distribuição observada do ângulo de fase. Os resíduos padronizados apresentaram distribuição aproximadamente normal, conforme demonstrado no gráfico de quantis teóricos dos efeitos aleatórios e no gráfico de normalidade dos resíduos, reforçando a adequação do modelo misto com intercepto aleatório por participante.

A homogeneidade da variância apresentou leve tendência de heterocedasticidade nas extremidades do ajuste, mas sem padrão grave de violação. A linearidade foi, em geral, respeitada, embora a tendência suavizada indique alguma curvatura para valores mais altos do desfecho. O gráfico de observações influentes mostrou que todos os pontos estão dentro dos limites de influência padronizada, indicando ausência de outliers com alavancagem elevada.

Por fim, a análise de colinearidade mostrou que todos os preditores apresentaram VIF abaixo de 3, descartando preocupações com multicolinearidade. Dessa forma, os pressupostos do modelo foram globalmente atendidos, validando a interpretação dos coeficientes estimados.

O modelo apresentou R² marginal de 0,250, indicando que as variáveis fixas explicam 25% da variância do desfecho, e R² condicional de 0,896, refletindo a alta variabilidade explicada quando se considera a estrutura aleatória intra-individual, compatível com o delineamento longitudinal do estudo.

# PCR

### 1

```{r}
model3 <- lmer(labs_crp ~ visit + allocation_group + (1 | record_id), data = data_filtered)

summary(model3)

plot(model3)  # Residuals vs. fitted

qqnorm(resid(model3)); qqline(resid(model3))  # Normality check
```

.

```{r}
model3_log <- lmer(log1p(labs_crp) ~ visit + allocation_group + (1 | record_id), data = data_filtered)
summary(model3_log)

plot(model3_log)

qqnorm(resid(model3_log)); qqline(resid(model3_log))  # Normality check
```

**log+1 transformation** to the skewed CRP variable, and the results show clear improvement.

| **Term** | **Estimate** | **p-value** | **Interpretation** |
|----------------|----------------|----------------|-------------------------|
| **Intercept** | 1.82 | \<0.001 | Mean **log(CRP + 1)** at baseline in Grupo A |
| **Visit** | –0.099 | 0.036 | **CRP decreases significantly over time** |
| **Grupo B (vs A)** | +0.139 | 0.405 | No significant difference at baseline |

The **effect of visit became statistically significant** (p = 0.036), whereas it was borderline before (p = 0.072).

**Diagnostic Plots** **Residuals vs. Fitted**

-   More **symmetrical and homoscedastic** than before.

-   No clear fan shape or funnel — much better than untransformed.

**Q-Q Plot**

-   **Much closer to the line**, indicating that residuals are approximately **normally distributed**.

-   A few expected mild deviations at the tails, but very acceptable.

**What does this mean in original CRP scale?**

Let’s back-transform the time effect:

-   Estimate for visit = –0.099

-   Since you’re modeling log1p(CRP), to interpret in original scale:

$$\\text{exp}(-0.099) = 0.9056$$

This means: **each visit is associated with \~9.4% decrease** in CRP over time, **on average**.

**Summary**

| **Point**          | **Result**                                |
|--------------------|-------------------------------------------|
| Residuals          | Look better: less heteroscedasticity      |
| Q-Q plot           | Much closer to normal                     |
| Time effect        | Now statistically significant (p = 0.036) |
| Log transformation | Successfully improved model performance   |

The idea is to explore the antiinflamatory effect of the intervention. Currently, the model assumes parallel time trends for both groups, i.e., it estimates:

-   A main effect of time (CRP changes over time),

-   A main effect of group (baseline difference),

-   But no interaction (i.e., it assumes both groups change equally over time).

*Why this is not enough*

If the intervention is effective, we expect:

-   CRP to decrease faster in the intervention group (Grupo B),

-   Which means there should be a significant interaction between visit and allocation_group.

*Model with interaction:*

-   Adds visit:allocation_groupGrupo B as an interaction term,

-   Tests whether CRP changes differently over time in Grupo B vs Grupo A.

```{r}
model3_log_inter <- lmer(log1p(labs_crp) ~ visit * allocation_group + (1 | record_id), data = data_filtered)

summary(model3_log_inter)

plot(model3_log_inter)

qqnorm(resid(model3_log_inter)); qqline(resid(model3_log_inter))  # Normality check
```

Key Result: No Significant Interaction • The term visit:allocation_groupGrupo B has p = 0.620, meaning: There is no statistical evidence that the intervention led to a greater reduction in CRP over time compared to control. • The trend for CRP decrease over time is similar in both groups.

Interpretation

Despite applying a more appropriate transformation and including the interaction: • Time still shows a mild (non-significant) decreasing trend in CRP. • No baseline difference between groups. • No enhanced effect in the intervention group.

This means that, based on your data, the intervention did not show a measurable anti-inflammatory effect on CRP.

*PLOT* plot shows: • Predicted log(CRP + 1) at each visit for each group. • Makes it easy to compare time trends across intervention and control groups on the same scale used in the model. • Useful for statistical interpretation and checking for meaningful differences.

```{r}
# Create a new data frame for prediction: all combinations of visit × group
new_data <- expand.grid(
  visit = unique(data_filtered$visit),
  allocation_group = unique(data_filtered$allocation_group)
)

# Predict fixed effects (marginal means, no random effects)
new_data$pred_log_crp <- predict(model3_log_inter, newdata = new_data, re.form = NA)

# Plot predicted log(CRP + 1)
ggplot(new_data, aes(x = visit, y = pred_log_crp, color = allocation_group, group = allocation_group)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  labs(
    title = "Predicted CRP over Time (log scale)",
    y = "Predicted log(CRP + 1)",
    x = "Visit",
    color = "Group"
  ) +
  theme_minimal(base_size = 14)
```

*Visual Insights*

-   Both groups show a downward trend in CRP over time, suggesting a general anti-inflammatory progression.

-   Grupo B starts at a higher baseline and appears to have a slightly steeper decline in log(CRP), although the interaction term was not statistically significant (p = 0.620).

This means that although Grupo B appears to improve more, this difference in slopes is not statistically supported.

*Grupo B's Higher Baseline*

Baseline imbalance may be a concern, particularly when:

1.  The groups were supposed to be randomized and equivalent at baseline, and

2.  The outcome variable (CRP, in this case) is already higher in one group before the intervention starts.

If Grupo B starts with higher CRP, then:

-   Any greater absolute reduction over time may be due to regression to the mean, not the intervention.

-   It violates the assumption that both groups are comparable at baseline, which undermines causal inference.

*Adjust for baseline differences:*

What this model does:

-   Adjusts for baseline CRP directly, reducing bias from initial imbalance.

-   The coefficient for allocation_groupGrupo B now reflects the difference at follow-up, controlling for baseline.

-   The time effect (visit) still captures change over time.

-   The model tests whether the intervention group had lower CRP over time than expected based on their higher starting levels.

If log1p_baseline_crp is significant, it means initial inflammation strongly predicts future levels — expected in longitudinal biomarkers.

If allocation_groupGrupo B or the visit:group interaction becomes significant after adjustment, that strengthens the case for a true treatment effect.

Let me know if you’d like to: • Visualize adjusted predictions • Back-transform to original CRP scale • Handle this in a subset of visits (e.g. only V1 and V3)

```{r}
# Adjusting for Baseline CRP in the Mixed Model (on log scale)

# Step 1: Create a baseline CRP variable (log-transformed)
# You should ensure that baseline CRP is correctly identified from your data

# Example: assuming visit 1 is baseline
data_filtered <- data_filtered %>%
  group_by(record_id) %>%
  mutate(log1p_baseline_crp = first(log1p(labs_crp[visit == 1]))) %>%
  ungroup()

# Step 2: Fit the adjusted model
model3_log_adj <- lmer(
  log1p(labs_crp) ~ visit + allocation_group + log1p_baseline_crp + (1 | record_id),
  data = data_filtered
)

# Step 3: Summarize the results
summary(model3_log_adj)
```

This model directly controls for **baseline differences in CRP**, correcting the bias introduced by the fact that **Grupo B started with higher inflammation**.

**Fixed Effects Summary**

| **Term** | **Estimate** | **p-value** | **Interpretation** |
|---------------|---------------|---------------|----------------------------|
| **(Intercept)** | 0.529 | \<0.001 | Estimated log(CRP+1) for Grupo A at baseline when baseline CRP is 0 |
| **visit** | –0.106 | **0.015** | CRP significantly **decreases over time** |
| **Grupo B (vs Grupo A)** | –0.008 | 0.919 | No difference between groups **after adjusting for baseline** |
| **log1p_baseline_crp** | +0.772 | \<0.001 | Strong predictor: higher baseline CRP leads to higher follow-up CRP |


**Key Takeaways**

-   **Time effect (visit) is now significant (p = 0.015)**:

    > CRP decreases over time **even after accounting for baseline**.

-   **Grupo B effect disappears (p = 0.919)**:

    > Once you adjust for baseline CRP, there’s **no evidence the intervention had a distinct effect** on CRP reduction compared to control.

-   **Baseline CRP is a major driver** of later CRP (β = 0.77, p \< 0.001).

**Interpretation**

The original difference in CRP trends between groups was likely due to **baseline imbalance**, not the intervention itself.

This adjusted model is **more reliable**, and the results suggest:

-   CRP decreases over time for all participants,

-   But the intervention **did not produce a differential anti-inflammatory effect**.

**Dropout Influence**

```{r}
#Step 1: Check the distribution of visits per subject
# Count number of observations per subject
dropout_check <- data_filtered %>%
  group_by(record_id) %>%
  summarize(n_visits = n_distinct(visit)) %>%
  count(n_visits)


#Step 2: Compare dropout by group
## Last visit per subject
last_visit_by_group <- data_filtered %>%
  group_by(record_id, allocation_group) %>%
  summarize(last_visit = max(visit)) %>%
  ungroup()

# Table: proportion reaching visit 3
table(last_visit_by_group$allocation_group, last_visit_by_group$last_visit)
# This checks whether Grupo B had more missing data at later visits than Grupo A — which could confound the CRP trajectory comparison.

#Step 3: Is dropout related to baseline CRP?
# If participants who dropped out had higher baseline CRP, your results may be biased due to non-random missingness (MNAR).

# Use the baseline CRP and check whether it's different in dropouts
baseline_dropout <- data_filtered %>%
  group_by(record_id) %>%
  mutate(last_visit = max(visit)) %>%
  filter(visit == 1) %>%
  mutate(dropped_out = last_visit < 3)

# Compare baseline CRP by dropout status
t.test(log1p(labs_crp) ~ dropped_out, data = baseline_dropout)
```

```         
•   Participants who dropped out had slightly lower CRP at baseline, but the difference is not statistically significant.
•   There’s no evidence that dropout was related to baseline inflammation.
•   Dropout appears to be random with respect to baseline CRP, which supports the Missing at Random (MAR) assumption.
```

Because: • The mixed-effects model (LMM) is valid under MAR, • There’s no significant baseline CRP difference between those who stayed and those who dropped out,

Your model results are likely unbiased with respect to dropout.

```{r}
# Back-transforming predicted log(CRP + 1) values to CRP (mg/L)

# Step 1: Create a prediction grid for all combinations of visit × group
# Use the median baseline CRP for prediction (in log1p scale)
baseline_crp_median <- median(log1p(baseline_dropout$labs_crp), na.rm = TRUE)

# Create grid of new data
new_data <- expand.grid(
  visit = unique(data_filtered$visit),
  allocation_group = unique(data_filtered$allocation_group)
) %>%
  mutate(log1p_baseline_crp = baseline_crp_median)

# Step 2: Predict from the adjusted model (fixed effects only)
new_data$pred_log <- predict(model3_log_adj, newdata = new_data, re.form = NA)

# Step 3: Back-transform
new_data$pred_crp <- exp(new_data$pred_log) - 1

# Step 4: Plot back-transformed predictions
ggplot(new_data, aes(x = visit, y = pred_crp, color = allocation_group, group = allocation_group)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 2.5) +
  labs(
    title = "Predicted CRP Levels Over Time (Back-Transformed)",
    x = "Visit",
    y = "Predicted CRP (mg/L)",
    color = "Group"
  ) +
  theme_minimal(base_size = 14)
```

What this plot shows

```         
•   Predicted CRP levels in mg/L, adjusted for the median baseline CRP.
•   Makes the model output clinically interpretable.
```

You can clearly see: • The overall downward trend in CRP over time. • That Grupo B does not differ from Grupo A in rate of CRP decline after adjusting for baseline.

```{r}
# add confidence intervals to predicted CRP plot (back-transformed)

# Load required packages
library(ggplot2)
library(dplyr)
library(merTools)  # for predictInterval

# Step 1: Create new data with baseline CRP held at median
baseline_crp_median <- median(log1p(baseline_dropout$labs_crp), na.rm = TRUE)

new_data <- expand.grid(
  visit = unique(data_filtered$visit),
  allocation_group = unique(data_filtered$allocation_group)
) %>%
  mutate(
    log1p_baseline_crp = baseline_crp_median,
    record_id = "dummy"  # Add a dummy ID to match model's grouping variable
  )

# Step 2: Get prediction intervals on log scale (includes uncertainty)
set.seed(123)  # for reproducibility
pred_int <- predictInterval(
  model3_log_adj,
  newdata = new_data,
  level = 0.95,
  n.sims = 1000,
  stat = "mean",
  type = "linear.prediction",
  include.resid.var = FALSE
)

# Combine with original new_data
new_data <- bind_cols(new_data, pred_int)

# Step 3: Back-transform
new_data <- new_data %>%
  mutate(
    fit = exp(fit) - 1,
    lwr = exp(lwr) - 1,
    upr = exp(upr) - 1
  )

# Step 4: Plot with ribbons (CI)
ggplot(new_data, aes(x = visit, y = fit, color = allocation_group, group = allocation_group)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 2.5) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = allocation_group), alpha = 0.2, color = NA) +
  labs(
    title = "Predicted CRP Levels with 95% CI (Back-Transformed)",
    y = "Predicted CRP (mg/L)",
    x = "Visit",
    color = "Group",
    fill = "Group"
  ) +
  theme_minimal(base_size = 14)
```

```{r}
# Optional: Line plot of individual trajectories
ggplot(data_filtered, aes(x = visit, y = labs_crp, group = record_id, color = allocation_group)) +
  geom_line(alpha = 0.3) +
  geom_point(alpha = 0.5) +
  labs(
    title = "Individual CRP Trajectories (Raw Data)",
    y = "Observed CRP (mg/L)",
    x = "Visit",
    color = "Group"
  ) +
  theme_minimal(base_size = 14)
```

### 2

```{r}
data_filtered_lmm <- data_filtered %>%
  group_by(record_id) %>%
  filter(n() > 1) %>%
  ungroup()

model4_log <- lmer(log1p(labs_crp) ~ visit + bmi + age + sex + dass_score_stress + 
     labs_hba1c + labs_ggt + labs_triglycerides + allocation_group + 
     (1 | record_id), data = data_filtered_lmm)

summary(model4_log)

plot(model3_log)

qqnorm(resid(model3_log)); qqline(resid(model3_log))  # Normality check```
```
